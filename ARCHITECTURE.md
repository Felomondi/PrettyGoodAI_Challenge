# Architecture

The bot uses Twilio to place outbound calls to the Athena test line. When a call connects, Flask serves TwiML that opens a `<Gather>` to listen — Athena speaks first, Twilio's built-in STT transcribes it, and the result is posted to a `/gather` webhook. From there, a two-tier response system decides what the patient says next: a regex pre-classifier handles predictable patterns instantly (staying silent through recording disclosures, brief acknowledgements during hold phrases, and an identity gate that keeps the bot silent until Athena says the patient's name), and GPT-4o-mini handles everything else, generating a contextual reply using the scenario goal, persona, and full conversation history. This keeps latency well under Twilio's 5-second webhook timeout while still producing natural, scenario-aware responses. After each call, the transcript is saved locally as both `.txt` and `.json`. Once all calls finish, a second GPT-4o-mini pass analyzes every transcript against the scenario's stated goal and expected agent behavior, producing a structured bug report grouped by severity.

The main design priority was minimizing moving parts. Twilio webhooks over plain HTTP were chosen over WebSockets because the request/response loop maps naturally to a turn-based phone conversation and needs no persistent connection management. Flask handles both the Twilio webhooks and the simulation UI in a single process — no separate servers. Patient identity is read directly from environment variables rather than a database, since the patient is already registered in Athena's system and we only need a name and date of birth to feed into the LLM prompt. ngrok is started programmatically on launch and automatically updates the Twilio webhook URL, so there is no manual configuration between runs. The UI exposes per-scenario run buttons rather than forcing a full suite run every time, which made iterating on individual failing scenarios significantly faster during development.